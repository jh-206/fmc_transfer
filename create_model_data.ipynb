{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f519b9c7-dec0-43ba-a7a1-73d453205c97",
   "metadata": {},
   "source": [
    "# Create Dataset for FMC Transfer Learning\n",
    "\n",
    "Using processed 1h, 10h, 100h, and 1000h data together with processed weather data. Run those notebooks first. Then see `ode_fit_tutorial` notebook for an explanation on using the timelag ODE to interpolate to hourly resolution data.\n",
    "\n",
    "Steps:\n",
    "1. Define train/val/test time periods\n",
    "2. For each FM observation, get 72 hours of preceeding hourly weather data and construct ML input sequences\n",
    "3. Construct corresponding target values in two scenarios: end-of-sequence observation and then hourly full sequence from reanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d24d6a8-c877-4c71-9f71-99eee311dd15",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82ad5a-8cf4-4f49-a4d4-a5a3534cd834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import read_yml, time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e1e1a-1e5d-4e86-9d4f-d8a252e2bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"data/ml_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c2f34-c9b5-41ae-9902-1daf7c9c6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_excel(\"data/processed_data/dvdk_weather.xlsx\")\n",
    "fm1 = pd.read_excel(\"data/processed_data/ok_1h.xlsx\")\n",
    "fm10 = pd.read_excel(\"data/processed_data/ok_10h.xlsx\")\n",
    "fm100 = pd.read_excel(\"data/processed_data/ok_100h.xlsx\")\n",
    "fm1000 = pd.read_excel(\"data/processed_data/ok_1000h.xlsx\")\n",
    "ode_params = read_yml(\"etc/params_models.yaml\", subkey=\"ode\")\n",
    "rnn_params = read_yml(\"models/params.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ba69b-6ffc-4c5c-a4cb-32545fb98677",
   "metadata": {},
   "source": [
    "## Define Time Periods\n",
    "\n",
    "Train: 1 full year starting from first date\n",
    "\n",
    "Val / Test: even split of remaining times\n",
    "\n",
    "NOTE: We choose 1 full year of train data so the temporal relationships can be learned in principle. But, we do not have a full year of test data in this structure. This a data limitation. Accuracy metrics will be conditional on the time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d4317-8428-4799-a0cf-b9fd119b9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates =  pd.concat([\n",
    "    fm1[\"utc_rounded\"],\n",
    "    fm10[\"utc_rounded\"],\n",
    "    fm100[\"utc_rounded\"],\n",
    "    fm1000[\"utc_rounded\"]])\n",
    "tmin, tmax = dates.min(), dates.max()\n",
    "\n",
    "# Train window\n",
    "train_start = tmin + pd.DateOffset(hours=72) # buffer at start to make sure full sequences\n",
    "train_end = tmin + pd.DateOffset(days=365)\n",
    "train_end = train_end + pd.DateOffset(hours=24) # Spinup period at start\n",
    "train_times = time_range(train_start, train_end, freq=\"1h\")\n",
    "\n",
    "# remaining window\n",
    "remaining_start = train_end\n",
    "remaining_end   = tmax\n",
    "\n",
    "# midpoint of remaining period\n",
    "midpoint = remaining_start + (remaining_end - remaining_start) / 2\n",
    "\n",
    "# validation and test\n",
    "val_start, val_end = remaining_start, midpoint\n",
    "val_times = time_range(val_start, val_end, freq=\"1h\")\n",
    "test_start, test_end = midpoint, remaining_end\n",
    "test_times = time_range(test_start, test_end, freq=\"1h\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Earlist FM Observation: {tmin}\")\n",
    "print(f\"Latest FM Observation: {tmax}\")\n",
    "print(f\"Train Period: {train_start} to {train_end}\")\n",
    "print(f\"    N. Hours: {train_times.shape[0]}\")\n",
    "print(f\"Val Period:   {val_start} to {val_end}\")\n",
    "print(f\"    N. Hours: {val_times.shape[0]}\")\n",
    "print(f\"Test Period:  {test_start} to {test_end}\")\n",
    "print(f\"    N. Hours: {test_times.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c178fd-c75f-417a-b97b-1cf73f887c3a",
   "metadata": {},
   "source": [
    "## Get Weather Data Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a57c54-8e80-4392-bd24-c5df2946f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = rnn_params[\"features_list\"]\n",
    "print(features_list)\n",
    "features_list_ok = ['Ed', 'Ew', 'solar', 'wind', 'rain', 'hod_utc', 'doy_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db5563-9c96-4e0f-8729-dcf1b91736fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static spatial features from Slapout Mesonet station\n",
    "elev =  774\n",
    "lon = -100.261920\n",
    "lat = 36.597490"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fc78c-171b-477d-ab54-16aa3b8bc841",
   "metadata": {},
   "source": [
    "### 1h Fuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f827a-38d5-4ce3-ba2e-dfc1f16d70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = fm1[(fm1.utc_rounded >= train_start) & (fm1.utc_rounded <= train_end)]\n",
    "n_samples = train1.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "X1 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, train1.shape[0]):\n",
    "    ti = train1.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    X1[i, :, :] = Xi    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce60ab-af77-422f-934a-da662a61f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = fm1[(fm1.utc_rounded >= val_start) & (fm1.utc_rounded <= val_end)]\n",
    "n_samples = val1.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "V1 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, val1.shape[0]):\n",
    "    ti = val1.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    V1[i, :, :] = Xi    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab7045-f2a1-498d-a4a0-2030bc1f3e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = fm1[(fm1.utc_rounded >= test_start) & (fm1.utc_rounded <= test_end)]\n",
    "n_samples = test1.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "T1 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, test1.shape[0]):\n",
    "    ti = test1.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    T1[i, :, :] = Xi    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43226854-dba1-4c27-9a59-584d9b5855cd",
   "metadata": {},
   "source": [
    "## 10h Fuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c61ca-3768-494c-96bd-6186f7b9b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train10 = fm10[(fm10.utc_rounded >= train_start) & (fm10.utc_rounded <= train_end)]\n",
    "n_samples = train10.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "X10 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, train10.shape[0]):\n",
    "    ti = train10.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    X10[i, :, :] = Xi   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edacfe8-0d9a-412b-a988-5c15f82a0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "val10 = fm10[(fm10.utc_rounded >= val_start) & (fm10.utc_rounded <= val_end)]\n",
    "n_samples = val10.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "V10 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, val10.shape[0]):\n",
    "    ti = val10.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    V10[i, :, :] = Xi    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792da74-1fe0-41d9-8e71-50b4fd478266",
   "metadata": {},
   "outputs": [],
   "source": [
    "test10 = fm10[(fm10.utc_rounded >= test_start) & (fm10.utc_rounded <= test_end)]\n",
    "n_samples = test10.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "T10 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, test10.shape[0]):\n",
    "    ti = test10.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    T10[i, :, :] = Xi    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a69b8-3852-4926-8701-ff13fd2a64e2",
   "metadata": {},
   "source": [
    "## 100h Fuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77c20d-31cd-491b-a375-e5549a75548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train100 = fm100[(fm100.utc_rounded >= train_start) & (fm100.utc_rounded <= train_end)]\n",
    "n_samples = train100.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "X100 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, train100.shape[0]):\n",
    "    ti = train100.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    X100[i, :, :] = Xi   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef847b5-a61b-40c0-a74b-a349df823cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val100 = fm100[(fm100.utc_rounded >= val_start) & (fm100.utc_rounded <= val_end)]\n",
    "n_samples = val100.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "V100 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, val100.shape[0]):\n",
    "    ti = val100.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    V100[i, :, :] = Xi    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e51d0-1686-4af3-858e-dedb0f8ac713",
   "metadata": {},
   "outputs": [],
   "source": [
    "test100 = fm100[(fm100.utc_rounded >= test_start) & (fm100.utc_rounded <= test_end)]\n",
    "n_samples = test100.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "T100 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, test100.shape[0]):\n",
    "    ti = test100.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    T100[i, :, :] = Xi    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbac310-145b-490b-b36d-dbaedaf5c131",
   "metadata": {},
   "source": [
    "## 1000h Fuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100858f3-40fe-4809-b454-c337136300a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1000 = fm1000[(fm1000.utc_rounded >= train_start) & (fm1000.utc_rounded <= train_end)]\n",
    "n_samples = train1000.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "X1000 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, train1000.shape[0]):\n",
    "    ti = train1000.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    X1000[i, :, :] = Xi   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbaf948-c466-4dc3-8680-42781dad4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val1000 = fm1000[(fm1000.utc_rounded >= val_start) & (fm1000.utc_rounded <= val_end)]\n",
    "n_samples = val1000.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "V1000 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, val1000.shape[0]):\n",
    "    ti = val1000.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    V1000[i, :, :] = Xi    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f51b0-767c-42ef-803d-45ff911e7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1000 = fm1000[(fm1000.utc_rounded >= test_start) & (fm1000.utc_rounded <= test_end)]\n",
    "n_samples = test1000.shape[0]\n",
    "seq_length   = 72\n",
    "n_feats   = len(features_list)\n",
    "T1000 = np.empty((n_samples, seq_length, n_feats), dtype=float)\n",
    "\n",
    "for i in range(0, test1000.shape[0]):\n",
    "    ti = test1000.iloc[i].utc_rounded\n",
    "    t0 = ti - pd.DateOffset(hours=seq_length)\n",
    "    wi = weather[(weather.utc > t0) & (weather.utc <= ti)][features_list_ok]\n",
    "    wi[\"hod\"] = wi[\"hod_utc\"]\n",
    "    wi[\"doy\"] = wi[\"doy_utc\"]\n",
    "    wi[\"elev\"] = elev\n",
    "    wi[\"lon\"] = lon\n",
    "    wi[\"lat\"] = lat\n",
    "    wi = wi[features_list] # call to ensure column order \n",
    "    Xi = wi.to_numpy()\n",
    "    # safety check\n",
    "    if Xi.shape != (seq_length, n_feats):\n",
    "        raise ValueError(f\"Bad shape at i={i}: {Xi.shape}\")\n",
    "\n",
    "    T1000[i, :, :] = Xi    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60e9d0-2c8c-4378-98e8-2a3944ccc47b",
   "metadata": {},
   "source": [
    "## Summaries and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49fe71-8c5a-40fc-a527-bdaef843f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FMC Data Summary\")\n",
    "print(f\"Ouput path: {output_dir}\")\n",
    "\n",
    "print(\"~\"*50)\n",
    "print(\"1h Fuels Summary\")\n",
    "print(f\"    Train Data:\")\n",
    "print(f\"         Weather Data: {X1.shape=}\")\n",
    "print(f\"         FM Data: {train1['fm1'].shape=}\")\n",
    "print(f\"    Val Data:\")\n",
    "print(f\"         Weather Data: {V1.shape=}\")\n",
    "print(f\"         FM Data: {val1['fm1'].shape=}\")\n",
    "print(f\"    Test Data:\")\n",
    "print(f\"         Weather Data: {T1.shape=}\")\n",
    "print(f\"         FM Data: {test1['fm1'].shape=}\")\n",
    "\n",
    "print(\"~\"*50)\n",
    "print(\"10h Fuels Summary\")\n",
    "print(f\"    Train Data:\")\n",
    "print(f\"         Weather Data: {X10.shape=}\")\n",
    "print(f\"         FM Data: {train10['fm10'].shape=}\")\n",
    "print(f\"    Val Data:\")\n",
    "print(f\"         Weather Data: {V10.shape=}\")\n",
    "print(f\"         FM Data: {val10['fm10'].shape=}\")\n",
    "print(f\"    Test Data:\")\n",
    "print(f\"         Weather Data: {T10.shape=}\")\n",
    "print(f\"         FM Data: {test10['fm10'].shape=}\")\n",
    "\n",
    "print(\"~\"*50)\n",
    "print(\"100h Fuels Summary\")\n",
    "print(f\"    Train Data:\")\n",
    "print(f\"         Weather Data: {X100.shape=}\")\n",
    "print(f\"         FM Data: {train100['fm100'].shape=}\")\n",
    "print(f\"    Val Data:\")\n",
    "print(f\"         Weather Data: {V100.shape=}\")\n",
    "print(f\"         FM Data: {val100['fm100'].shape=}\")\n",
    "print(f\"    Test Data:\")\n",
    "print(f\"         Weather Data: {T100.shape=}\")\n",
    "print(f\"         FM Data: {test100['fm100'].shape=}\")\n",
    "\n",
    "print(\"~\"*50)\n",
    "print(\"1000h Fuels Summary\")\n",
    "print(f\"    Train Data:\")\n",
    "print(f\"         Weather Data: {X1000.shape=}\")\n",
    "print(f\"         FM Data: {train1000['fm1000'].shape=}\")\n",
    "print(f\"    Val Data:\")\n",
    "print(f\"         Weather Data: {V1000.shape=}\")\n",
    "print(f\"         FM Data: {val1000['fm1000'].shape=}\")\n",
    "print(f\"    Test Data:\")\n",
    "print(f\"         Weather Data: {T1000.shape=}\")\n",
    "print(f\"         FM Data: {test1000['fm1000'].shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84019674-f21e-488f-a14c-78ddb38e9949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6992d-4e02-4080-aedf-5ced803dcda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
