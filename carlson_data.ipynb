{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723c6dce-fc1b-4be0-97bd-35066ffdc531",
   "metadata": {},
   "source": [
    "# Fuel Field Observations from Oklahoma\n",
    "\n",
    "The purpose of this notebook is to clean and format data received from JD Carlson (via Derek Vanderkamp) on fuel moisture field observations conducted in Oklahoma in 1996-1997.\n",
    "\n",
    "## Background\n",
    "\n",
    "- Part of publication in 2007\n",
    "- Used to calibrate Nelson model, used by many agencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa915e35-ecc3-46dc-b193-8ad5db378e34",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93968cb-04d5-4feb-881c-b340fa6e3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import time_intp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2489d-f0d5-4d5c-9695-b5dc262aa0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/oklahoma_Carlson_data.xlsx\")\n",
    "\n",
    "output_dir = \"data/processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785202e1-e036-4c8d-848d-2162b867c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50e190-58d5-446a-bd3a-ec3e6a6e8eb5",
   "metadata": {},
   "source": [
    "## Explore\n",
    "\n",
    "Carlson Data from Derek Vanderkamp:\n",
    "\n",
    "- Includes weather data and fuel moisture data.\n",
    "- Weather data and fuel moisture data not exactly lined up in time\n",
    "- Separate rows with missing weather or missing fuel moisture if not at the same time\n",
    "\n",
    "GOAL:\n",
    "NOTE: Running this process for 1h, 10h, 100h, and 1000h separately\n",
    "\n",
    "- Separate weather from FMC data\n",
    "- Sort by time\n",
    "- Interpolate weather to line up to exact time of FMC data\n",
    "- Join back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decde319-6329-4c81-8ec2-dfb38e52e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique sites: {len(df.site.unique())}\")\n",
    "print(f\"Unique subsites: {len(df.subsite.unique())}\")\n",
    "print(f\"Unique res: {len(df.res.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b1ee1-1dcf-461c-aa1f-0c54951b79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff9956f-d503-4a9c-b156-ad05d30d2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Variable Sets\n",
    "tvars = [\"year\", \"month\", \"yday\", \"mday\", \"hour\", \"min\", \"date\"]\n",
    "wvars = [\"k.down\", \"precip\", \"rh\", \"temp\", \"vap.press\", \"vpd\",\n",
    "         \"wind.speed\", \"vap.den\"]\n",
    "fvars = [\"fuel.mois_1h\", \"fuel.mois\", \"fuel.mois_100h\", \"fuel.mois_1000h\"] # 1h, 10h, 100h, and 1000h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5922257-55d6-47bd-9597-e493ae4832ca",
   "metadata": {},
   "source": [
    "### Fix Date\n",
    "The date column as received in the spreadsheet has a couple of missing dates, and the 0 hour dates are read in oddly. Check both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4151c-7b29-434c-8eda-a18d456cf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct date\n",
    "dates = pd.to_datetime(dict(\n",
    "    year=df['year'],\n",
    "    month=df['month'],\n",
    "    day=df['mday'],\n",
    "    hour=df['hour'],\n",
    "    minute=df['min']\n",
    "))\n",
    "\n",
    "print(f\"Number of NA Dates: {np.sum(dates.isna())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4ed3c-3acd-467c-a3b7-bb2aa76c1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 0 hour dates\n",
    "df[df.hour == 0][tvars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8657160c-9be0-4ded-8cf0-dbdea52b9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that hour and minute info is in timestamp\n",
    "print(df[df.hour == 0][tvars].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdab95-3c80-4908-a6b6-843ba9173d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.hour == 0]['date'].dt.hour.unique())\n",
    "print(df[df.hour == 0]['date'].dt.minute.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67540294-ae72-4159-9bca-a943116818dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to date column in data frame, manually extract\n",
    "inds = np.where(dates != df.date)[0]\n",
    "print(f\"Number of Date Mismatches: {len(inds)}\")\n",
    "print(f\"Number of Missing Dates: {np.sum(df.date.isna())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9070a68-aa54-48ef-89c4-ea6300f66cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually Investigate\n",
    "print(dates.iloc[inds])\n",
    "df.iloc[inds][tvars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5da52f-70f2-46eb-8f54-3e5647f66ab8",
   "metadata": {},
   "source": [
    "**NOTE:** the manually constructed date column exists for all but a couple of NA dates in the spreadsheet. We will replace the date column with the manually constructed one to overwrite the two missing dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630c7d1-e744-4fc6-a445-15bada2e78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = dates\n",
    "\n",
    "print(f\"Number of Missing Dates: {np.sum(df.date.isna())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e0242-57a5-4369-ae05-4113144a18b5",
   "metadata": {},
   "source": [
    "### Separate Datasets\n",
    "\n",
    "Note: filtering FMC data by fuel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6827bc-d5d0-41b4-9504-9489742db9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fm_class(df0, fuel_class,\n",
    "                 tvars = [\"year\", \"month\", \"yday\", \"mday\", \"hour\", \"min\", \"date\"], \n",
    "                 wvars = [\"k.down\", \"precip\", \"rh\", \"temp\", \"vap.press\", \"vpd\", \"wind.speed\", \"vap.den\"]):\n",
    "\n",
    "    # Extract fuel data\n",
    "    fm = df[tvars + fvars]\n",
    "    fm = fm.rename(columns={\n",
    "        'fuel.mois_1h': 'fm1', \n",
    "        'fuel.mois': 'fm10', \n",
    "        'fuel.mois_100h': 'fm100',\n",
    "        'fuel.mois_1000h': 'fm1000', \n",
    "    })\n",
    "    if fuel_class == \"1h\":\n",
    "        fm = fm[~(fm['fm1'].isna())]\n",
    "        fm = fm.drop(columns = [\"fm10\", \"fm100\", \"fm1000\"])\n",
    "    elif fuel_class == \"10h\":\n",
    "        fm = fm[~(fm['fm10'].isna())]\n",
    "        fm = fm.drop(columns = [\"fm1\", \"fm100\", \"fm1000\"])\n",
    "    elif fuel_class == \"100h\":\n",
    "        fm = fm[~(fm['fm100'].isna())]\n",
    "        fm = fm.drop(columns = [\"fm1\", \"fm10\", \"fm1000\"])\n",
    "    elif fuel_class == \"1000h\":\n",
    "        fm = fm[~(fm['fm1000'].isna())]\n",
    "        fm = fm.drop(columns = [\"fm1\", \"fm10\", \"fm100\"])\n",
    "    \n",
    "    # Sort by time\n",
    "    fm = fm.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bad3cf-daf4-4d04-b49a-68b5b7f8b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm1 = get_fm_class(df, fuel_class = \"1h\")\n",
    "fm10 = get_fm_class(df, fuel_class = \"10h\")\n",
    "fm100 = get_fm_class(df, fuel_class = \"100h\")\n",
    "fm1000 = get_fm_class(df, fuel_class = \"1000h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b04ab6-947d-4841-8e11-c3278450ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weather data\n",
    "weather = df[tvars + wvars]\n",
    "weather = weather[~(weather.rh.isna()) & ~(weather.temp.isna())]\n",
    "weather = weather.sort_values(\"date\").reset_index(drop=True)\n",
    "weather = weather[['date'] + wvars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b834d8-cc33-41ab-af31-98d5e89b8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Time\n",
    "wlag = weather.date.diff()\n",
    "\n",
    "u = wlag.dropna().unique()\n",
    "print(f\"Weather Time Range:\\n    {weather.date.min()} to {weather.date.max()}\")\n",
    "print(f\"Weather time increments: {u}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9155bb55-dece-4191-8ceb-8d6397441ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = fm1.date.diff()\n",
    "u = flag.dropna().unique()\n",
    "print(f\"FM 1h Time Range:\\n    {fm1.date.min()} to {fm1.date.max()}\")\n",
    "print(f\"FM 1h time increments: \")\n",
    "print(f\"    Min increment: {u.min()}\")\n",
    "print(f\"    Max increment: {u.max()}\")\n",
    "print(f\"    Mean increment: {u.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0893dd3-1048-43b2-92f2-3b09cd9ce95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = fm10.date.diff()\n",
    "u = flag.dropna().unique()\n",
    "print(f\"FM 10h Time Range:\\n    {fm10.date.min()} to {fm10.date.max()}\")\n",
    "print(f\"FM 10h time increments: \")\n",
    "print(f\"    Min increment: {u.min()}\")\n",
    "print(f\"    Max increment: {u.max()}\")\n",
    "print(f\"    Mean increment: {u.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85cfc86-2782-4fd7-818c-44a3d5bb51bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = fm100.date.diff()\n",
    "u = flag.dropna().unique()\n",
    "print(f\"FM 100h Time Range:\\n    {fm100.date.min()} to {fm100.date.max()}\")\n",
    "print(f\"FM 100h time increments: \")\n",
    "print(f\"    Min increment: {u.min()}\")\n",
    "print(f\"    Max increment: {u.max()}\")\n",
    "print(f\"    Mean increment: {u.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274e5ee-568a-4bbc-a542-ef975e8e8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = fm1000.date.diff()\n",
    "u = flag.dropna().unique()\n",
    "print(f\"FM 1000h Time Range:\\n    {fm1000.date.min()} to {fm1000.date.max()}\")\n",
    "print(f\"FM 1000h time increments: \")\n",
    "print(f\"    Min increment: {u.min()}\")\n",
    "print(f\"    Max increment: {u.max()}\")\n",
    "print(f\"    Mean increment: {u.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228dd43-ff80-4d82-a56f-86ed5091247c",
   "metadata": {},
   "source": [
    "## Interpolate Weather and Join\n",
    "\n",
    "Line up weather data with exact time of FM observation with temporal interpolation. Using linear interp for now. Weather is higher resolution in time so linear is sensible. \n",
    "\n",
    "Programmatically: \n",
    "- set date colomn to index in weather data\n",
    "- use numpy interp on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209daea-5a9c-4fcf-8e6b-2665c7a4f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_weather_to_fm(w2: pd.DataFrame, fm: pd.DataFrame, date_col: str = \"date\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Align weather data (w2) to the irregular fm timestamps.\n",
    "    - Numeric columns: linear interpolation in time (inside range only).\n",
    "    - Non-numeric columns: forward fill then backfill.\n",
    "    - Returns a DataFrame with rows exactly at fm[date_col] times.\n",
    "    \"\"\"\n",
    "    w2 = w2.copy()\n",
    "    f = fm[[date_col]].copy()\n",
    "\n",
    "    # Ensure datetime\n",
    "    w2[date_col] = pd.to_datetime(w2[date_col], utc=False)\n",
    "    f[date_col] = pd.to_datetime(f[date_col], utc=False)\n",
    "\n",
    "    # Drop duplicates and sort\n",
    "    w2 = w2.drop_duplicates(subset=[date_col]).sort_values(date_col)\n",
    "    f = f.drop_duplicates(subset=[date_col]).sort_values(date_col)\n",
    "\n",
    "    # Indexing\n",
    "    w2 = w2.set_index(date_col)\n",
    "    fm_times = pd.DatetimeIndex(f[date_col])\n",
    "\n",
    "    # Union index for interpolation anchors and targets\n",
    "    combined_idx = w2.index.union(fm_times)\n",
    "\n",
    "    # Reindex and interpolate\n",
    "    w2r = w2.reindex(combined_idx)\n",
    "\n",
    "    num_cols = w2r.select_dtypes(include=[np.number]).columns\n",
    "    non_num_cols = w2r.columns.difference(num_cols)\n",
    "\n",
    "    if len(num_cols) > 0:\n",
    "        w2r[num_cols] = w2r[num_cols].interpolate(method='time', limit_area='inside')\n",
    "\n",
    "    if len(non_num_cols) > 0:\n",
    "        w2r[non_num_cols] = w2r[non_num_cols].ffill().bfill()\n",
    "\n",
    "    # Select rows at fm times\n",
    "    aligned = w2r.loc[fm_times].copy()\n",
    "    aligned = aligned.assign(**{date_col: fm_times})\n",
    "    cols = [date_col] + [c for c in aligned.columns if c != date_col]\n",
    "    aligned = aligned[cols]\n",
    "\n",
    "    return aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e85c3e-090d-4f1e-85d1-b80ca2a918e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = align_weather_to_fm(weather, fm1)\n",
    "w10 = align_weather_to_fm(weather, fm10)\n",
    "w100 = align_weather_to_fm(weather, fm100)\n",
    "w1000 = align_weather_to_fm(weather, fm1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deafa09-dd50-48f6-80da-1f7dd69e588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check before merge\n",
    "print(f\"{w1.shape[0]=}, Matches FM data: {w1.shape[0] == fm1.shape[0]}\")\n",
    "print(f\"Date Columns Match: {np.all(w1.date.values == fm1.date.values)}\")\n",
    "print()\n",
    "print(f\"{w10.shape[0]=}, Matches FM data: {w10.shape[0] == fm10.shape[0]}\")\n",
    "print(f\"Date Columns Match: {np.all(w10.date.values == fm10.date.values)}\")\n",
    "print()\n",
    "print(f\"{w100.shape[0]=}, Matches FM data: {w100.shape[0] == fm100.shape[0]}\")\n",
    "print(f\"Date Columns Match: {np.all(w100.date.values == fm100.date.values)}\")\n",
    "print()\n",
    "print(f\"{w1000.shape[0]=}, Matches FM data: {w1000.shape[0] == fm1000.shape[0]}\")\n",
    "print(f\"Date Columns Match: {np.all(w1000.date.values == fm1000.date.values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701ff90-b3ec-4e37-bd58-d97daba86aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "fm1 = pd.concat([fm1.reset_index(drop=True), w1.drop(columns=['date']).reset_index(drop=True)], axis=1)\n",
    "fm10 = pd.concat([fm10.reset_index(drop=True), w10.drop(columns=['date']).reset_index(drop=True)], axis=1)\n",
    "fm100 = pd.concat([fm100.reset_index(drop=True), w100.drop(columns=['date']).reset_index(drop=True)], axis=1)\n",
    "fm1000 = pd.concat([fm1000.reset_index(drop=True), w1000.drop(columns=['date']).reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0906d0-b3bb-4f64-9cec-2cfcd6ce5317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check an interpolated time\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Get the FM timestamp at index 0\n",
    "test_time = fm1.loc[0, 'date']\n",
    "\n",
    "print(\"FM time:\", test_time)\n",
    "\n",
    "# Pull the two nearest weather rows before/after this FM time\n",
    "mask = (weather['date'] <= test_time)\n",
    "before = weather.loc[mask].tail(1)\n",
    "after = weather.loc[~mask].head(1)\n",
    "\n",
    "print(\"\\nWeather row before/after:\")\n",
    "display(pd.concat([before, after]))\n",
    "\n",
    "print(\"\\nInterpolated weather row (from final):\")\n",
    "display(fm1.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c497ef-feda-4ff6-bd3a-727332d23edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Out\n",
    "fm1.to_excel(\"data/processed_data/ok_data_1h.xlsx\", index=False)\n",
    "fm10.to_excel(\"data/processed_data/ok_data_10h.xlsx\", index=False)\n",
    "fm100.to_excel(\"data/processed_data/ok_data_100h.xlsx\", index=False)\n",
    "fm1000.to_excel(\"data/processed_data/ok_data_1000h.xlsx\", index=False)\n",
    "\n",
    "weather.to_excel(\"data/processed_data/ok_weather.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3426ac-863e-437d-a37b-f7949dc63f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f8329-c2e3-463e-bb91-c5def92701d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
