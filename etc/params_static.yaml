# File used to store hyperparameters.


xgb:
  features_list: ['Ed', 'Ew', 'solar', 'wind', 'elev', 'lon', 'lat', 'rain', 'hod', 'doy'] 
  max_depth: 3            # maximum tree depth
  eta: 0.1                # Learning rate
  min_child_weight: 1     # minimum sum of Hessian of samples needed to make a partition
  subsample: 0.8          # Percent of training data to be randomly selected in each boosting iteration
  colsample_bytree: 0.9   # Percent of features to be randomly selected in each boosting iteration
  scale_pos_weight: 1     
  n_estimators: 100       # number of trees in ensemble
  gamma: .1               # minimum loss reduction required to make a tree partition
  scaler: 'standard'      # for consistency with RNN, but XGB doesn't require scaling 


  ### Params sent by Schreck that use VIIRS and other inputs, slower and less accurate for this dataset
    # objective: "reg:squarederror"
    # n_splits: 1
    # learning_rate: 0.1 
    # n_estimators: 1000
    # max_depth: 10
    # n_jobs: 8
    # colsample_bytree: 0.8995496645826047
    # gamma: 0.6148001693726943
    # learning_rate: 0.07773680788294579
    # max_depth: 10 
    # subsample: 0.7898672617361431
    # metric: "valid_rmse"



lm:
  fit_intercept: true
  scaler: null  
