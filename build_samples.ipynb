{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff3832a-c0bd-499f-9489-70f75edd4191",
   "metadata": {},
   "source": [
    "# Building Samples from Irregularly Sampled Timeseries\n",
    "\n",
    "This notebook proposes a way to build samples for sequence learning tasks given an observed timeseries with irregular sampling intervals. The FMC data from the Carlson field study was sampled 2x daily, and we want to be able to train models that predict FMC hourly or even subhourly. \n",
    "\n",
    "Input sequences for training will still be 48-hours, hourly weather data. Response variable sequences will be length 48 with missing value placeholders (-9999), and then a loss function will mask them out properly to calculate loss ~4 times over the 48-hour sequence. \n",
    "\n",
    "Stride length is a hyperparam. Stride length 1 moves the 48-hour window over 1 hour at a time, maximizing data but making highly correlated samples. In principle, it could be tuned, but we will opt to the average response variable frequency of 12hrs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608b11e4-46c3-4e2e-801f-9f19a8fe705a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb1c4c5-8111-40f3-8d06-91e947e21286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import time_intp, read_yml, Dict\n",
    "from src.reproducibility import set_seed\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70430fe2-d397-4498-a593-312184659029",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_excel(\"data/processed_data/dvdk_weather.xlsx\")\n",
    "fm = pd.read_excel(\"data/processed_data/ok_100h.xlsx\")\n",
    "\n",
    "conf = Dict(read_yml(\"etc/thesis_config.yaml\"))\n",
    "params = Dict(read_yml(\"models/params.yaml\"))\n",
    "scaler = joblib.load(\"models/scaler.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5615a89-c016-4535-ab9c-6bc7dbc107c4",
   "metadata": {},
   "source": [
    "## Build Sparse Response-Variable Sequences\n",
    "\n",
    "Given a set of sparsely observed FM values, get weather data at that time and a lookup period back in time.\n",
    "\n",
    "Steps:\n",
    "- Define train/val/test period\n",
    "  - For Carlson data, only 1 location so can't do spatial holdout\n",
    "- For train, build 48-hour sequences of weather and response, fill mask -9999 in missing\n",
    "- For test and val, get all data and keep sequential order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53282cdc-b50e-4351-b1a3-373f1ffa01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine weather and fm, fill na, add geographic features\n",
    "df = weather.merge(\n",
    "    fm[[\"utc_rounded\", \"utc_prov\", \"fm100\"]],\n",
    "    left_on=\"utc\",\n",
    "    right_on=\"utc_rounded\",\n",
    "    how=\"left\"\n",
    ").drop(columns=\"utc_rounded\")\n",
    "\n",
    "df[\"elev\"] = conf.ok_elev\n",
    "df[\"lon\"] = conf.ok_lon\n",
    "df[\"lat\"] = conf.ok_lat\n",
    "\n",
    "df[\"fm100\"] = df[\"fm100\"].fillna(-9999)\n",
    "df[[\"utc\", \"utc_prov\", \"fm100\", \"lon\", \"lat\", \"elev\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bbc208-3404-4f51-ba88-6c997de65b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split times\n",
    "X_train = df[(df.utc >= conf.train_start) & (df.utc <= conf.train_end)][params.features_list]\n",
    "y_train = df[(df.utc >= conf.train_start) & (df.utc <= conf.train_end)][\"fm100\"].to_numpy()\n",
    "\n",
    "X_val = df[(df.utc >= conf.val_start) & (df.utc <= conf.val_end)][params.features_list]\n",
    "y_val = df[(df.utc >= conf.val_start) & (df.utc <= conf.val_end)][\"fm100\"].to_numpy()\n",
    "\n",
    "X_test  = df[(df.utc >= conf.f_start) & (df.utc <= conf.f_end)][params.features_list]\n",
    "y_test = df[(df.utc >= conf.f_start) & (df.utc <= conf.f_end)][\"fm100\"].to_numpy()\n",
    "\n",
    "print(f\"{X_train.shape=}\")\n",
    "print(f\"{y_train.shape=}\")\n",
    "print(f\"{X_val.shape=}\")\n",
    "print(f\"{y_val.shape=}\")\n",
    "print(f\"{X_test.shape=}\")\n",
    "print(f\"{y_test.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f25cbd-316b-4a18-a637-4452baa81b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale using saved scaler object from RNN, reshape val and test to 3d array\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "XX_val = scaler.transform(X_val)\n",
    "XX_val = XX_val.reshape(1, *XX_val.shape)\n",
    "\n",
    "XX_test = scaler.transform(X_test)\n",
    "XX_test = XX_test.reshape(1, *XX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cca6f4-5780-46e9-a2b8-fccfb9b5b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consistent 1h time steps, should be 1hr unique time diff plut NaT at the start:\n",
    "\n",
    "print(df.utc.diff().unique()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9902bb2-d49b-4387-90a5-4e9c7812fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_batches_univariate(X, y, seq_length=48, stride_length=12, mask_val=-9999):\n",
    "    \"\"\"\n",
    "    Build fixed-length sequence samples from an hourly univariate time series.\n",
    "\n",
    "    Inputs\n",
    "    - X: array-like, shape (N, n_features)\n",
    "    - y: array-like, shape (N,)\n",
    "         Response with missing labels encoded as mask_val.\n",
    "    - seq_length: int\n",
    "         Sequence length (e.g., 48 hours).\n",
    "    - stride_legnth: int\n",
    "        Number of time steps to shift sequence legnth window\n",
    "    - mask_val: float\n",
    "         Sentinel value indicating missing y.\n",
    "\n",
    "    Returns \n",
    "    - X: np.ndarray, shape (n_samples, seq_length, n_features)\n",
    "    - y: np.ndarray, shape (n_samples, seq_length, 1)\n",
    "    - mask: np.ndarray, shape (n_samples, seq_length)  (1 where observed, 0 where missing)\n",
    "    \"\"\"\n",
    "\n",
    "    # Checks\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(f\"X must be 2D (N, n_features). Got shape {X.shape}\")\n",
    "    if y.ndim != 1:\n",
    "        raise ValueError(f\"y must be 1D (N,). Got shape {y.shape}\")\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(f\"X and y must have same length. Got {len(X)} and {len(y)}\")\n",
    "    if seq_length <= 0:\n",
    "        raise ValueError(\"seq_length must be > 0\")\n",
    "    if stride_length <= 0:\n",
    "        raise ValueError(\"stride_length must be > 0\")\n",
    "    N = len(y)\n",
    "    if N < seq_length:\n",
    "        raise ValueError(f\"Need N >= seq_length. Got N={N}, seq_length={seq_length}\")\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    mask_list = []\n",
    "    for start in range(0, N - seq_length + 1, stride_length):\n",
    "        X_i = X[start:(start+seq_length),:]\n",
    "        y_i = y[start:(start+seq_length)]\n",
    "        mask_i = (y_i != mask_val)\n",
    "        X_list.append(X_i); y_list.append(y_i); mask_list.append(mask_i)\n",
    "    \n",
    "\n",
    "    XX = np.array(X_list); yy = np.array(y_list)[..., np.newaxis]; mask = np.array(mask_list)\n",
    "    return XX, yy, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673f82f-af3c-47f8-b234-1da5c805c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_samples, y_train_samples, masks = build_training_batches_univariate(X = X_train_scaled, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0ab14-348a-4d8a-b058-0ed028fc83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{X_train_samples.shape=}\")\n",
    "print(f\"{y_train_samples.shape=}\")\n",
    "print(f\"{masks.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e6c8d-0ff8-491e-b39b-067fdab771ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check masking:\n",
    "print(y_train_samples[0,:,0])\n",
    "print(y_train_samples[0,masks[0],0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c7adb5-ffc6-487b-82dd-fe2380721f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7ccd1-dbfe-4911-bf4a-73e8469040ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f865abd-9595-48e8-9296-4e87793f771f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7e5aa-dabe-4b14-a06a-d3014a476ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6adcf-cae9-4521-a490-ae605ba16fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
