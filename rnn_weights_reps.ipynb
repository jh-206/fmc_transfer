{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe2a669-36e6-4bd0-af26-940816b072b8",
   "metadata": {},
   "source": [
    "# RNN Weight Replications Analysis\n",
    "\n",
    "Examine variability in RMSE for training and validation sets.\n",
    "\n",
    "NOTE: the RNN was trained with a training set from 2023-2024, and the validation set was only used to control early stopping. The estimated forecast accuracy was performed with a full train/val/test split with test set all of 2024. The final model trains over all available data and uses the estimated forecast accuracy from the spatiotemporal analysis.\n",
    "\n",
    "The replications for this analysis varied the random seed for order of training samples (batch or mini-batch order), random sample of physical stations for train vs val sets, and initial weights of the RNN. The training set is fixed. So the variability in the replications is meant to estimate the uncertainty introduced by the gradient descent algorithm. \n",
    "\n",
    "The purpose of this is to examine whether the RNN is estimating the same function over replications, and to make stronger conclusions about what the time warping does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9723c2-49e1-4a27-a012-f54517c98254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from src.models import moisture_rnn as mrnn\n",
    "from src.utils import read_yml, time_intp, plot_styles, str2time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1aa422-1a65-41a5-904b-e299a1411b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Trained model\n",
    "params = read_yml(\"models/params.yaml\")\n",
    "rnn = mrnn.RNN_Flexible(params=params)\n",
    "scaler = joblib.load(\"models/scaler.joblib\")\n",
    "rnn.load_weights('models/rnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08666724-6740-4cb8-8185-40d4fd74eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight replications\n",
    "rep_dirs = os.listdir(\"models/reps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89449213-0ec5-441a-8dea-b3c186614d75",
   "metadata": {},
   "source": [
    "## Fitting Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4712d-422e-4751-868f-df928e5c19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = []\n",
    "val_mse = []\n",
    "n_train = []\n",
    "n_val   = []\n",
    "\n",
    "base_path = \"models/reps\"\n",
    "\n",
    "for d in rep_dirs:\n",
    "    csv_path = os.path.join(base_path, d, \"fitting_mse.csv\")\n",
    "    \n",
    "    if not os.path.isfile(csv_path):\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    train_val = df.loc[df[\"set\"] == \"train\", \"mse\"].values\n",
    "    train_n_val   = df.loc[df[\"set\"] == \"train\", \"n_samples\"].values\n",
    "    val_val   = df.loc[df[\"set\"] == \"val\", \"mse\"].values\n",
    "    val_n_val     = df.loc[df[\"set\"] == \"val\", \"n_samples\"].values\n",
    "    \n",
    "    train_mse.append(train_val[0])\n",
    "    n_train.append(train_n_val[0])\n",
    "    val_mse.append(val_val[0])\n",
    "    n_val.append(val_n_val[0])\n",
    "\n",
    "train_mse = np.array(train_mse)\n",
    "n_train = np.array(n_train)\n",
    "val_mse = np.array(val_mse)\n",
    "n_val = np.array(n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2e7f8-8787-4027-a558-dff765a6fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- RMSE stats (sqrt applied after aggregation) ----\n",
    "train_mean = np.sqrt(np.mean(train_mse))\n",
    "train_std  = np.sqrt(np.std(train_mse))\n",
    "train_low  = np.sqrt(np.min(train_mse))\n",
    "train_high = np.sqrt(np.max(train_mse))\n",
    "\n",
    "\n",
    "# ---- N stats (no sqrt) ----\n",
    "train_n_mean = int(np.round(np.mean(n_train)))\n",
    "train_n_std  = int(np.round(np.std(n_train)))\n",
    "\n",
    "train_row = [\n",
    "    f\"{train_mean:.2f} $\\\\pm$ {train_std:.2f}\",\n",
    "    f\"({train_low:.2f}, {train_high:.2f})\",\n",
    "    f\"{train_n_mean:,} $\\\\pm$ {train_n_std:,}\"\n",
    "]\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"RMSE (Mean $\\\\pm$ SD)\",\n",
    "        \"RMSE Range (Low, High)\",\n",
    "        \"N (Mean $\\\\pm$ SD)\"\n",
    "    ],\n",
    "    \"Values\": [\n",
    "        f\"{train_mean:.2f} $\\\\pm$ {train_std:.2f}\",\n",
    "        f\"({train_low:.2f}, {train_high:.2f})\",\n",
    "        f\"{train_n_mean:,} $\\\\pm$ {train_n_std:,}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0466067-b566-4d4d-88d6-eecc4a9fdef6",
   "metadata": {},
   "source": [
    "## Parameter Distributions\n",
    "\n",
    "Forget Gate and Input Gate bias terms are a random realization of a 64-length vector, and should be permutation invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85fff7-7023-47e3-8a5b-78cb4b8fd72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = []\n",
    "bi = []\n",
    "\n",
    "for d in rep_dirs:\n",
    "    weight_path = os.path.join(base_path, d, \"rnn.weights.h5\")\n",
    "    f = h5py.File(weight_path, 'r')\n",
    "    cell_vars = f['layers']['lstm']['cell']['vars']\n",
    "    arrays = {k: cell_vars[k][()] for k in cell_vars.keys()}\n",
    "    b = arrays['2']\n",
    "    units = b.shape[0] // 4\n",
    "    bf.append(b[units:2*units])\n",
    "    bi.append(b[0:units])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bee138-4f1e-42ae-af5f-b14da982dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = np.array(bf)\n",
    "bi = np.array(bi)\n",
    "diff = np.array(bf-bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edae1e-15c2-4dc5-b136-d66482f334d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Stats\n",
    "# Forget gate\n",
    "bf_model_means = np.mean(bf, axis=1)\n",
    "bf_between_mean = np.mean(bf_model_means)\n",
    "bf_between_std  = np.std(bf_model_means)\n",
    "\n",
    "bf_model_sds = np.std(bf, axis=1)\n",
    "bf_mean_model_sd = np.mean(bf_model_sds)\n",
    "bf_sd_model_sd   = np.std(bf_model_sds)\n",
    "\n",
    "bf_mean_low  = np.min(bf_model_means)\n",
    "bf_mean_high = np.max(bf_model_means)\n",
    "\n",
    "bf_sd_low  = np.min(bf_model_sds)\n",
    "bf_sd_high = np.max(bf_model_sds)\n",
    "\n",
    "\n",
    "# Input gate\n",
    "bi_model_means = np.mean(bi, axis=1)\n",
    "bi_between_mean = np.mean(bi_model_means)\n",
    "bi_between_std  = np.std(bi_model_means)\n",
    "\n",
    "bi_model_sds = np.std(bi, axis=1)\n",
    "bi_mean_model_sd = np.mean(bi_model_sds)\n",
    "bi_sd_model_sd   = np.std(bi_model_sds)\n",
    "\n",
    "bi_mean_low  = np.min(bi_model_means)\n",
    "bi_mean_high = np.max(bi_model_means)\n",
    "\n",
    "bi_sd_low  = np.min(bi_model_sds)\n",
    "bi_sd_high = np.max(bi_model_sds)\n",
    "\n",
    "# Diff\n",
    "diff_model_means = np.mean(diff, axis=1)\n",
    "diff_between_mean = np.mean(diff_model_means)\n",
    "diff_between_std  = np.std(diff_model_means)\n",
    "\n",
    "diff_model_sds = np.std(diff, axis=1)\n",
    "diff_mean_model_sd = np.mean(diff_model_sds)\n",
    "diff_sd_model_sd   = np.std(diff_model_sds)\n",
    "\n",
    "diff_mean_low  = np.min(diff_model_means)\n",
    "diff_mean_high = np.max(diff_model_means)\n",
    "\n",
    "diff_sd_low  = np.min(diff_model_sds)\n",
    "diff_sd_high = np.max(diff_model_sds)\n",
    "\n",
    "\n",
    "bf_row = [\n",
    "    \"Forget Gate Bias\",\n",
    "    f\"{bf_between_mean:.2f} $\\\\pm$ {bf_between_std:.2f}\",\n",
    "    f\"({bf_mean_low:.2f}, {bf_mean_high:.2f})\",\n",
    "    f\"{bf_mean_model_sd:.2f} $\\\\pm$ {bf_sd_model_sd:.2f}\",\n",
    "    f\"({bf_sd_low:.2f}, {bf_sd_high:.2f})\",\n",
    "]\n",
    "\n",
    "bi_row = [\n",
    "    \"Input Gate Bias\",\n",
    "    f\"{bi_between_mean:.2f} $\\\\pm$ {bi_between_std:.2f}\",\n",
    "    f\"({bi_mean_low:.2f}, {bi_mean_high:.2f})\",\n",
    "    f\"{bi_mean_model_sd:.2f} $\\\\pm$ {bi_sd_model_sd:.2f}\",\n",
    "    f\"({bi_sd_low:.2f}, {bi_sd_high:.2f})\",\n",
    "]\n",
    "\n",
    "diff_row = [\n",
    "    \"Difference\",\n",
    "    f\"{diff_between_mean:.2f} $\\\\pm$ {diff_between_std:.2f}\",\n",
    "    f\"({diff_mean_low:.2f}, {diff_mean_high:.2f})\",\n",
    "    f\"{diff_mean_model_sd:.2f} $\\\\pm$ {diff_sd_model_sd:.2f}\",\n",
    "    f\"({diff_sd_low:.2f}, {diff_sd_high:.2f})\",\n",
    "]\n",
    "\n",
    "# table\n",
    "table = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Mean of per-model means ($\\\\pm$ SD across reps)\",\n",
    "        \"Range of per-model means (low, high)\",\n",
    "        \"Mean of per-model SDs ($\\\\pm$ SD across reps)\",\n",
    "        \"Range of per-model SDs (low, high)\",\n",
    "    ],\n",
    "    \"Forget Gate Bias\": bf_row[1:],\n",
    "    \"Input Gate Bias\": bi_row[1:],\n",
    "    \"Difference\": diff_row[1:]\n",
    "})\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb965fa-4e59-4b51-875d-477c056ba9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document-safe viz defaults\n",
    "DPI = 300\n",
    "LABEL_SIZE = 14\n",
    "TICK_SIZE = 12\n",
    "CBAR_LABEL_SIZE = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1683610a-debf-4f55-aa51-23550063eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# bi assumed shape (n_reps, n_units)\n",
    "n_reps, n_units = bi.shape\n",
    "\n",
    "# Compute SD per replication\n",
    "rep_sds = bi.std(axis=1)\n",
    "sorted_idx = np.argsort(rep_sds)  # ascending (lowest SD first → highest SD last)\n",
    "\n",
    "# Define common x-grid\n",
    "xmin = np.min(bi)\n",
    "xmax = np.max(bi)\n",
    "x_grid = np.linspace(xmin, xmax, 400)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 10), sharex=True, dpi=DPI)\n",
    "\n",
    "# ---------- Left: Original (unsorted) ----------\n",
    "axes[0].axvline(bi.mean(), linestyle='--', linewidth=1.5, alpha=.4)\n",
    "offset = 0\n",
    "offset_step = 0.4\n",
    "\n",
    "for r in range(n_reps):\n",
    "    kde = gaussian_kde(bi[r, :])\n",
    "    density = kde(x_grid)\n",
    "    density = density / density.max() * 0.35\n",
    "\n",
    "    axes[0].fill_between(\n",
    "        x_grid,\n",
    "        offset,\n",
    "        density + offset,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    offset += offset_step\n",
    "\n",
    "axes[0].set_xlim(-3.5, 3.5)\n",
    "axes[0].set_title(\"Input Gate Bias Distribution Across Replications\", fontsize=LABEL_SIZE)\n",
    "axes[0].set_xlabel(r\"Input Gate Bias ($b_i$)\", fontsize=LABEL_SIZE)\n",
    "axes[0].set_yticks([])\n",
    "axes[0].tick_params(labelsize=TICK_SIZE)\n",
    "\n",
    "# ---------- Right: Sorted by SD ----------\n",
    "axes[1].axvline(bi.mean(), linestyle='--', linewidth=1.5, alpha=.4)\n",
    "offset = 0\n",
    "\n",
    "for r in sorted_idx:\n",
    "    kde = gaussian_kde(bi[r, :])\n",
    "    density = kde(x_grid)\n",
    "    density = density / density.max() * 0.35\n",
    "\n",
    "    axes[1].fill_between(\n",
    "        x_grid,\n",
    "        offset,\n",
    "        density + offset,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    offset += offset_step\n",
    "\n",
    "axes[1].set_xlim(-3.5, 3.5)\n",
    "axes[1].set_title(\n",
    "    \"Sorted by Replication SD\\n(High Variance to Low Variance)\",\n",
    "    fontsize=LABEL_SIZE\n",
    ")\n",
    "axes[1].set_xlabel(r\"Input Gate Bias ($b_i$)\", fontsize=LABEL_SIZE)\n",
    "axes[1].set_yticks([])\n",
    "axes[1].tick_params(labelsize=TICK_SIZE)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/bi_hist.png\", dpi=DPI)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb683c-d8da-454d-87da-36d0c0dd0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# bf assumed shape (n_reps, n_units)\n",
    "n_reps, n_units = bf.shape\n",
    "\n",
    "# Compute SD per replication for sorting\n",
    "rep_sds = bf.std(axis=1)\n",
    "sorted_idx = np.argsort(rep_sds)  # ascending\n",
    "\n",
    "# Define common x-grid\n",
    "xmin = np.min(bf)\n",
    "xmax = np.max(bf)\n",
    "x_grid = np.linspace(xmin, xmax, 400)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# ---------- Left: Original (unsorted) ----------\n",
    "axes[0].axvline(bf.mean(), linestyle='--', linewidth=1.5, alpha=.4)\n",
    "offset = 0\n",
    "offset_step = 0.4\n",
    "\n",
    "for r in range(n_reps):\n",
    "    kde = gaussian_kde(bf[r, :])\n",
    "    density = kde(x_grid)\n",
    "    density = density / density.max() * 0.35\n",
    "\n",
    "    axes[0].fill_between(\n",
    "        x_grid,\n",
    "        offset,\n",
    "        density + offset,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    offset += offset_step\n",
    "\n",
    "axes[0].set_xlim(-3.5, 3.5)\n",
    "axes[0].set_title(\"Forget Gate Bias Distributions Across Replications\", fontsize=LABEL_SIZE)\n",
    "axes[0].set_xlabel(r\"Forget Gate Bias ($b_f$)\", fontsize=LABEL_SIZE)\n",
    "axes[0].set_yticks([])\n",
    "axes[0].tick_params(labelsize=TICK_SIZE)\n",
    "\n",
    "# ---------- Right: Sorted by SD ----------\n",
    "axes[1].axvline(bf.mean(), linestyle='--', linewidth=1.5, alpha=.4)\n",
    "offset = 0\n",
    "\n",
    "for r in sorted_idx:\n",
    "    kde = gaussian_kde(bf[r, :])\n",
    "    density = kde(x_grid)\n",
    "    density = density / density.max() * 0.35\n",
    "\n",
    "    axes[1].fill_between(\n",
    "        x_grid,\n",
    "        offset,\n",
    "        density + offset,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    offset += offset_step\n",
    "\n",
    "axes[1].set_xlim(-3.5, 3.5)\n",
    "axes[1].set_title(\"Sorted by Replication SD\\n(High Variance to Low Variance)\", fontsize=LABEL_SIZE)\n",
    "axes[1].set_xlabel(r\"Forget Gate Bias ($b_f$)\", fontsize=LABEL_SIZE)\n",
    "axes[1].set_yticks([])\n",
    "axes[1].tick_params(labelsize=TICK_SIZE)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/bf_hist.png\", dpi=DPI)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a21f7-5a69-44a0-b19f-83b243667d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Difference\n",
    "diff = bf - bi\n",
    "n_reps, n_units = diff.shape\n",
    "\n",
    "# Compute SD per replication\n",
    "rep_sds = diff.std(axis=1)\n",
    "\n",
    "# Sort high variance → low variance\n",
    "sorted_idx = np.argsort(rep_sds)[::-1]\n",
    "\n",
    "# Common x-grid\n",
    "xmin = np.min(diff)\n",
    "xmax = np.max(diff)\n",
    "x_grid = np.linspace(xmin, xmax, 400)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# ---------- Left: Original (unsorted) ----------\n",
    "axes[0].axvline(diff.mean(), linestyle='--', linewidth=1.5, alpha=.4)\n",
    "offset = 0\n",
    "offset_step = 0.4\n",
    "\n",
    "for r in range(n_reps):\n",
    "    kde = gaussian_kde(diff[r, :])\n",
    "    density = kde(x_grid)\n",
    "    density = density / density.max() * 0.35\n",
    "\n",
    "    axes[0].fill_between(\n",
    "        x_grid,\n",
    "        offset,\n",
    "        density + offset,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    offset += offset_step\n",
    "\n",
    "axes[0].set_xlim(-3.5, 3.5)\n",
    "axes[0].set_title(\"Bias Difference Distributions Across Replications\", fontsize=LABEL_SIZE)\n",
    "axes[0].set_xlabel(r\"Difference ($b_f - b_i$)\", fontsize=LABEL_SIZE)\n",
    "axes[0].set_yticks([])\n",
    "axes[0].tick_params(labelsize=TICK_SIZE)\n",
    "\n",
    "# ---------- Right: Sorted High → Low SD ----------\n",
    "axes[1].axvline(diff.mean(), linestyle='--', linewidth=1.5, alpha=.4)\n",
    "offset = 0\n",
    "\n",
    "for r in sorted_idx[::-1]:\n",
    "    kde = gaussian_kde(diff[r, :])\n",
    "    density = kde(x_grid)\n",
    "    density = density / density.max() * 0.35\n",
    "\n",
    "    axes[1].fill_between(\n",
    "        x_grid,\n",
    "        offset,\n",
    "        density + offset,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    offset += offset_step\n",
    "\n",
    "axes[1].set_xlim(-3.5, 3.5)\n",
    "axes[1].set_title(\n",
    "    \"Sorted by Replication SD\\n(High Variance to Low Variance)\",\n",
    "    fontsize=LABEL_SIZE\n",
    ")\n",
    "axes[1].set_xlabel(r\"Difference ($b_f - b_i$)\", fontsize=LABEL_SIZE)\n",
    "axes[1].set_yticks([])\n",
    "axes[1].tick_params(labelsize=TICK_SIZE)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/diff_hist.png\", dpi=DPI)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028c8ef-5129-43fd-be7d-8fc9d0e67bc0",
   "metadata": {},
   "source": [
    "## Other Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3605c16-967f-4a78-9649-ae94bbc1103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import anderson_ksamp\n",
    "\n",
    "# X: shape (n_reps, n_units), e.g. diff, bf, or bi\n",
    "X = bf\n",
    "n_reps, n_units = X.shape\n",
    "\n",
    "# Each replication is one sample\n",
    "samples = [X[r, :] for r in range(n_reps)]\n",
    "\n",
    "# Run k-sample Anderson–Darling test\n",
    "result = anderson_ksamp(samples)\n",
    "\n",
    "print(\"AD statistic:\", result.statistic)\n",
    "print(\"Critical values:\", result.critical_values)\n",
    "print(\"Significance level (%):\", result.significance_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7735431-9b7a-473d-a1e1-eca8835c2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: shape (n_reps, n_units), e.g. diff, bf, or bi\n",
    "X = bi\n",
    "n_reps, n_units = X.shape\n",
    "\n",
    "# Each replication is one sample\n",
    "samples = [X[r, :] for r in range(n_reps)]\n",
    "\n",
    "# Run k-sample Anderson–Darling test\n",
    "result = anderson_ksamp(samples)\n",
    "\n",
    "print(\"AD statistic:\", result.statistic)\n",
    "print(\"Critical values:\", result.critical_values)\n",
    "print(\"Significance level (%):\", result.significance_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d37e6-bad8-456e-bdc4-584006661517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: shape (n_reps, n_units), e.g. diff, bf, or bi\n",
    "X = diff\n",
    "n_reps, n_units = X.shape\n",
    "\n",
    "# Each replication is one sample\n",
    "samples = [X[r, :] for r in range(n_reps)]\n",
    "\n",
    "# Run k-sample Anderson–Darling test\n",
    "result = anderson_ksamp(samples)\n",
    "\n",
    "print(\"AD statistic:\", result.statistic)\n",
    "print(\"Critical values:\", result.critical_values)\n",
    "print(\"Significance level (%):\", result.significance_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5512de4-1b1a-49e5-ac03-60620334cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "X = diff\n",
    "n_reps, n_units = X.shape\n",
    "\n",
    "# Pooled empirical distribution\n",
    "pooled = X.ravel()\n",
    "\n",
    "rows = []\n",
    "for r in range(n_reps):\n",
    "    D, p = ks_2samp(X[r, :], pooled, alternative=\"two-sided\", method=\"auto\")\n",
    "    rows.append((r, D, p))\n",
    "\n",
    "ks_results = pd.DataFrame(rows, columns=[\"rep\", \"KS_distance\", \"p_value\"])\n",
    "ks_results = ks_results.sort_values(\"KS_distance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "ks_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc42f1-b68a-4a6f-bcaa-cd5964662b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
