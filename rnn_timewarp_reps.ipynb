{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe2a669-36e6-4bd0-af26-940816b072b8",
   "metadata": {},
   "source": [
    "# RNN Weight Replications Analysis\n",
    "\n",
    "Examine variability in RMSE for training and validation sets.\n",
    "\n",
    "NOTE: the RNN was trained with a training set from 2023-2024, and the validation set was only used to control early stopping. The estimated forecast accuracy was performed with a full train/val/test split with test set all of 2024. The final model trains over all available data and uses the estimated forecast accuracy from the spatiotemporal analysis.\n",
    "\n",
    "The replications for this analysis varied the random seed for order of training samples (batch or mini-batch order), random sample of physical stations for train vs val sets, and initial weights of the RNN. The training set is fixed. So the variability in the replications is meant to estimate the uncertainty introduced by the gradient descent algorithm. \n",
    "\n",
    "The purpose of this is to examine whether the RNN is estimating the same function over replications, and to make stronger conclusions about what the time warping does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9723c2-49e1-4a27-a012-f54517c98254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from src.models import moisture_rnn as mrnn\n",
    "from src.utils import read_yml, time_intp, plot_styles, str2time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1aa422-1a65-41a5-904b-e299a1411b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Trained model\n",
    "params = read_yml(\"models/params.yaml\")\n",
    "rnn = mrnn.RNN_Flexible(params=params)\n",
    "scaler = joblib.load(\"models/scaler.joblib\")\n",
    "rnn.load_weights('models/rnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08666724-6740-4cb8-8185-40d4fd74eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight replications\n",
    "rep_dirs = os.listdir(\"models/reps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89449213-0ec5-441a-8dea-b3c186614d75",
   "metadata": {},
   "source": [
    "## Fitting Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4712d-422e-4751-868f-df928e5c19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = []\n",
    "val_mse = []\n",
    "n_train = []\n",
    "n_val   = []\n",
    "\n",
    "base_path = \"models/reps\"\n",
    "\n",
    "for d in rep_dirs:\n",
    "    csv_path = os.path.join(base_path, d, \"fitting_mse.csv\")\n",
    "    \n",
    "    if not os.path.isfile(csv_path):\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    train_val = df.loc[df[\"set\"] == \"train\", \"mse\"].values\n",
    "    train_n_val   = df.loc[df[\"set\"] == \"train\", \"n_samples\"].values\n",
    "    val_val   = df.loc[df[\"set\"] == \"val\", \"mse\"].values\n",
    "    val_n_val     = df.loc[df[\"set\"] == \"val\", \"n_samples\"].values\n",
    "    \n",
    "    train_mse.append(train_val[0])\n",
    "    n_train.append(train_n_val[0])\n",
    "    val_mse.append(val_val[0])\n",
    "    n_val.append(val_n_val[0])\n",
    "\n",
    "train_mse = np.array(train_mse)\n",
    "n_train = np.array(n_train)\n",
    "val_mse = np.array(val_mse)\n",
    "n_val = np.array(n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2e7f8-8787-4027-a558-dff765a6fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- RMSE stats (sqrt applied after aggregation) ----\n",
    "train_mean = np.sqrt(np.mean(train_mse))\n",
    "train_std  = np.sqrt(np.std(train_mse))\n",
    "train_low  = np.sqrt(np.min(train_mse))\n",
    "train_high = np.sqrt(np.max(train_mse))\n",
    "\n",
    "val_mean = np.sqrt(np.mean(val_mse))\n",
    "val_std  = np.sqrt(np.std(val_mse))\n",
    "val_low  = np.sqrt(np.min(val_mse))\n",
    "val_high = np.sqrt(np.max(val_mse))\n",
    "\n",
    "# ---- N stats (no sqrt) ----\n",
    "train_n_mean = int(np.round(np.mean(n_train)))\n",
    "train_n_std  = int(np.round(np.std(n_train)))\n",
    "\n",
    "val_n_mean = int(np.round(np.mean(n_val)))\n",
    "val_n_std  = int(np.round(np.std(n_val)))\n",
    "\n",
    "train_row = [\n",
    "    \"Train\",\n",
    "    f\"{train_mean:.2f} $\\\\pm$ {train_std:.2f}\",\n",
    "    f\"({train_low:.2f}, {train_high:.2f})\",\n",
    "    f\"{train_n_mean:,} $\\\\pm$ {train_n_std:,}\"\n",
    "]\n",
    "\n",
    "val_row = [\n",
    "    \"Val\",\n",
    "    f\"{val_mean:.2f} $\\\\pm$ {val_std:.2f}\",\n",
    "    f\"({val_low:.2f}, {val_high:.2f})\",\n",
    "    f\"{val_n_mean:,} $\\\\pm$ {val_n_std:,}\"\n",
    "]\n",
    "\n",
    "table = pd.DataFrame(\n",
    "    [train_row, val_row],\n",
    "    columns=[\n",
    "        \"Data Sample\",\n",
    "        \"Mean RMSE ($\\\\pm$ SD)\",\n",
    "        \"Range of RMSE (Low, High)\",\n",
    "        \"Mean N. ($\\\\pm$ SD)\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0466067-b566-4d4d-88d6-eecc4a9fdef6",
   "metadata": {},
   "source": [
    "## Parameter Distributions\n",
    "\n",
    "Forget Gate and Input Gate bias terms are a random realization of a 64-length vector, and should be permutation invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85fff7-7023-47e3-8a5b-78cb4b8fd72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = []\n",
    "bi = []\n",
    "\n",
    "for d in rep_dirs:\n",
    "    weight_path = os.path.join(base_path, d, \"rnn.weights.h5\")\n",
    "    f = h5py.File(weight_path, 'r')\n",
    "    cell_vars = f['layers']['lstm']['cell']['vars']\n",
    "    arrays = {k: cell_vars[k][()] for k in cell_vars.keys()}\n",
    "    b = arrays['2']\n",
    "    units = b.shape[0] // 4\n",
    "    bf.append(b[units:2*units])\n",
    "    bi.append(b[0:units])\n",
    "\n",
    "bf = np.array(bf)\n",
    "bi = np.array(bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edae1e-15c2-4dc5-b136-d66482f334d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forget gate\n",
    "bf_model_means = np.mean(bf, axis=1)\n",
    "bf_between_mean = np.mean(bf_model_means)\n",
    "bf_between_std  = np.std(bf_model_means)\n",
    "\n",
    "bf_model_sds = np.std(bf, axis=1)\n",
    "bf_mean_model_sd = np.mean(bf_model_sds)\n",
    "bf_sd_model_sd   = np.std(bf_model_sds)\n",
    "\n",
    "bf_mean_low  = np.min(bf_model_means)\n",
    "bf_mean_high = np.max(bf_model_means)\n",
    "\n",
    "bf_sd_low  = np.min(bf_model_sds)\n",
    "bf_sd_high = np.max(bf_model_sds)\n",
    "\n",
    "\n",
    "# Input gate\n",
    "bi_model_means = np.mean(bi, axis=1)\n",
    "bi_between_mean = np.mean(bi_model_means)\n",
    "bi_between_std  = np.std(bi_model_means)\n",
    "\n",
    "bi_model_sds = np.std(bi, axis=1)\n",
    "bi_mean_model_sd = np.mean(bi_model_sds)\n",
    "bi_sd_model_sd   = np.std(bi_model_sds)\n",
    "\n",
    "bi_mean_low  = np.min(bi_model_means)\n",
    "bi_mean_high = np.max(bi_model_means)\n",
    "\n",
    "bi_sd_low  = np.min(bi_model_sds)\n",
    "bi_sd_high = np.max(bi_model_sds)\n",
    "\n",
    "\n",
    "bf_row = [\n",
    "    \"Forget Gate Bias\",\n",
    "    f\"{bf_between_mean:.2f} $\\\\pm$ {bf_between_std:.2f}\",\n",
    "    f\"({bf_mean_low:.2f}, {bf_mean_high:.2f})\",\n",
    "    f\"{bf_mean_model_sd:.2f} $\\\\pm$ {bf_sd_model_sd:.2f}\",\n",
    "    f\"({bf_sd_low:.2f}, {bf_sd_high:.2f})\",\n",
    "]\n",
    "\n",
    "bi_row = [\n",
    "    \"Input Gate Bias\",\n",
    "    f\"{bi_between_mean:.2f} $\\\\pm$ {bi_between_std:.2f}\",\n",
    "    f\"({bi_mean_low:.2f}, {bi_mean_high:.2f})\",\n",
    "    f\"{bi_mean_model_sd:.2f} $\\\\pm$ {bi_sd_model_sd:.2f}\",\n",
    "    f\"({bi_sd_low:.2f}, {bi_sd_high:.2f})\",\n",
    "]\n",
    "\n",
    "\n",
    "table = pd.DataFrame(\n",
    "    [bf_row, bi_row],\n",
    "    columns=[\n",
    "        \"Parameter\",\n",
    "        \"Mean of per-model means ($\\\\pm$ SD across reps)\",\n",
    "        \"Range of per-model means (low, high)\",\n",
    "        \"Mean of per-model SDs ($\\\\pm$ SD across reps)\",\n",
    "        \"Range of per-model SDs (low, high)\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023799a-4418-499f-8728-f50c8a48bdce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70178226-0011-4b47-98a2-5004c7f94613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed068741-5b61-4db5-8af3-69ddf018ea4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
